{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3: Model Optimisation\n",
    "\n",
    "## Exercise 2: Xgboost with Hyperopt\n",
    "\n",
    "We will train a Xgboost model on the same dataset as previously usiong Hyperopt.\n",
    "\n",
    "\n",
    "**Pre-requisites:**\n",
    "- Create a github account (https://github.com/join)\n",
    "- Install git (https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)\n",
    "- Install Docker (https://docs.docker.com/get-docker/)\n",
    "\n",
    "The steps are:\n",
    "1.   Launch Docker image\n",
    "2.   Load Data\n",
    "3.   Train Xgboost model with defauly hyperparameter\n",
    "4.   Hyperparameter tuning with Hyperopt\n",
    "5.   Push changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Launch Docker image\n",
    "docker run  -dit --rm --name adv_dsi_lab_3 -p 8888:8888 -e JUPYTER_ENABLE_LAB=yes -v ~/Projects/adv_dsi/adv_dsi_lab_3:/home/jovyan/work -v ~/.aws:/home/jovyan/.aws -v ~/Projects/adv_dsi/src:/home/jovyan/work/src xgboost-notebook:latest \n",
    "docker logs --tail 50 adv_dsi_lab_2\n",
    "\n",
    "# Create a new git branch called xgboost_hyperopt\n",
    "git checkout -b xgboost_hyperopt\n",
    "\n",
    "# Navigate the folder notebooks and create a new jupyter notebook called 2_xgboost_hyperopt.ipynb\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "**[2.1]** Import the function you created `load_sets` from `src/data/sets`\n",
    "\n",
    "**[2.2]** Load the saved sets from `data/processed`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function you created load_sets from src/data/sets\n",
    "from src.data.sets import load_sets\n",
    "\n",
    "# Load the saved sets from data/processed\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Xgboost model\n",
    "\n",
    "**[3.1]** Import the xgboost package as xgb\n",
    "\n",
    "**[3.2]** Instantiate the RandomForest class into a variable called rf with random_state=8\n",
    "\n",
    "**[3.3]** Task: Fit the model with the prepared data\n",
    "\n",
    "**[3.4]** Import `dump` from `joblib` and save the fitted model into the folder `models` as a file called `xgboost_default`\n",
    "\n",
    "**[3.5]** Save the predictions from this model for the training and validation sets into 2 variables called `y_train_preds` and `y_val_preds`\n",
    "\n",
    "**[3.6]** Import `print_reg_perf` from `src/models/performance` and display the accuracy and f1 scores of this baseline model on the training and validation sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training: 0.9211552214945801\n",
      "F1 Training      : 0.9208732214873642\n",
      "Accuracy Validation: 0.9068593424622957\n",
      "F1 Validation      : 0.9063573849035116\n"
     ]
    }
   ],
   "source": [
    "# Import the xgboost package as xgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# instantiate the XGBClassifier class into a variable called xgboost1\n",
    "xgboost1 = xgb.XGBClassifier()\n",
    "\n",
    "# Fit the model with the prepared data\n",
    "xgboost1.fit(X_train, y_train)\n",
    "print(xgboost1.fit(X_train, y_train))\n",
    "\n",
    "# Import dump from joblib and save the fitted model into the folder models as a file called xgboost_default\n",
    "from joblib import dump \n",
    "dump(xgboost1,  '../models/xgboost_default.joblib')\n",
    "\n",
    "# Save the predictions from this model for the training and validation sets into 2 variables called y_train_preds and y_val_preds\n",
    "y_train_preds = xgboost1.predict(X_train)\n",
    "y_val_preds = xgboost1.predict(X_val)\n",
    "\n",
    "from src.models.performance import print_class_perf\n",
    "\n",
    "print_class_perf(y_preds=y_train_preds, y_actuals=y_train, set_name='Training', average='weighted')\n",
    "print_class_perf(y_preds=y_val_preds, y_actuals=y_val, set_name='Validation', average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter tuning with Hyperopt\n",
    "\n",
    "**[4.1]** Import Trials, STATUS_OK, tpe, hp, fmin from hyperopt package\n",
    "\n",
    "**[4.2]** Define the search space for xgboost hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Trials, STATUS_OK, tpe, hp, fmin from hyperopt package\n",
    "from hyperopt import Trials, STATUS_OK, tpe, hp, fmin\n",
    "\n",
    "# Define the search space for xgboost hyperparameters\n",
    "space = {\n",
    "    'max_depth' : hp.choice('max_depth', range(5, 20, 1)),\n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.05),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'subsample' : hp.quniform('subsample', 0.1, 1, 0.05),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.05)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4.3]** Define a function called `objective` with the following logics:\n",
    "- input parameters: hyperparameter seacrh space (`space`)\n",
    "- logics: train a xgboost model with the search space and calculate the average accuracy score for cross validation with 10 folds\n",
    "- output parameters: dictionary with the loss score and STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function called objective\n",
    "def objective(space):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    xgboost = xgb.XGBClassifier(\n",
    "        max_depth = int(space['max_depth']),\n",
    "        learning_rate = space['learning_rate'],\n",
    "        min_child_weight = space['min_child_weight'],\n",
    "        subsample = space['subsample'],\n",
    "        colsample_bytree = space['colsample_bytree']\n",
    "    )\n",
    "    \n",
    "    acc = cross_val_score(xgboost, X_train, y_train, cv=10, scoring=\"accuracy\").mean()\n",
    "\n",
    "    return{'loss': 1-acc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4.4]** Launch Hyperopt search and save the result in a variable called `best`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [23:15<00:00, 279.19s/trial, best loss: 0.1020389329003667] \n"
     ]
    }
   ],
   "source": [
    "# Launch Hyperopt search and save the result in a variable called `best`\n",
    "best = fmin(\n",
    "    fn=objective,   \n",
    "    space=space,       \n",
    "    algo=tpe.suggest,       \n",
    "    max_evals=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4.5]** Print the best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best:  {'colsample_bytree': 0.9500000000000001, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 4.0, 'subsample': 0.25}\n"
     ]
    }
   ],
   "source": [
    "# Print the best set of hyperparameters\n",
    "print(\"Best: \", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4.6]** Instantiate a XGBClassifier with best set of hyperparameters\n",
    "\n",
    "**[4.7]** Fit the model with the prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.9500000000000001, gamma=0,\n",
       "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.25, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=4.0, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=0.25,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a XGBClassifier with best set of hyperparameters\n",
    "xgboost2 = xgb.XGBClassifier(\n",
    "    max_depth = best['max_depth'],\n",
    "    learning_rate = best['learning_rate'],\n",
    "    min_child_weight = best['min_child_weight'],\n",
    "    subsample = best['subsample'],\n",
    "    colsample_bytree = best['colsample_bytree']\n",
    ")\n",
    "\n",
    "# Fit the model with the prepared data\n",
    "xgboost2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4.8]** Display the accuracy and f1 scores of this baseline model on the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training: 0.9243174264839926\n",
      "F1 Training      : 0.9240612030551106\n",
      "Accuracy Validation: 0.9039776193180623\n",
      "F1 Validation      : 0.9035708202543029\n"
     ]
    }
   ],
   "source": [
    "# Display the accuracy and f1 scores of this baseline model on the training and validation sets\n",
    "print_class_perf(y_preds=xgboost2.predict(X_train), y_actuals=y_train, set_name='Training', average='weighted')\n",
    "print_class_perf(y_preds=xgboost2.predict(X_val), y_actuals=y_val, set_name='Validation', average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4.9]** Save the fitted model into the folder models as a file called `xgboost_best`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/xgboost_best.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fitted model into the folder models as a file called `xgboost_best`\n",
    "dump(xgboost2,  '../models/xgboost_best.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Push changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Add you changes to git staging area\n",
    "# Create the snapshot of your repository and add a description\n",
    "# Push your snapshot to Github\n",
    "\n",
    "git add .   \n",
    "git commit -m \"commit 3 xgboost\"\n",
    "git push https://*********@github.com/CazMayhem/adv_dsi_lab_3.git\n",
    "\n",
    "# Check out to the master branch\n",
    "# Pull the latest updates\n",
    "\n",
    "git checkout master\n",
    "git pull https://*********@github.com/CazMayhem/adv_dsi_lab_3.git\n",
    "\n",
    "# Check out to the data_prep branch\n",
    "# Merge the master branch and push your changes\n",
    "git checkout xgboost_hyperopt\n",
    "git merge master\n",
    "git push https://*********@github.com/CazMayhem/adv_dsi_lab_3.git\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[5.8]** Go to Github and merge the branch after reviewing the code and fixing any conflict\n",
    "\n",
    "\n",
    "**[5.9]** Stop the Docker container\n",
    "\n",
    "=> docker stop adv_dsi_lab_3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
